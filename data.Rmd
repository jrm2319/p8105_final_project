---
title: "DATA"
author: "Erynne Jackson"
date: "2024-12-01"
output: github_document
---

```{r}

library(readxl)
library(tidyverse)
library(readr)

```

Cleaning the Books file. 
```{r}

url = "https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/refs/heads/master/books.csv"
books = read_csv(url)

view(books)
```

Cleaning the Ratings file.  
```{r}

url2 = "https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/refs/heads/master/ratings.csv"
ratings = read_csv(url2)

view(ratings)

```

Cleaning the Book Tags file.  
```{r}
url3 = "https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/refs/heads/master/book_tags.csv"
book_tag = read_csv(url3)

view(book_tag)
```


Cleaning the Tags file. 
```{r}

url4 = "https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/refs/heads/master/tags.csv"
tags = read_csv(url4)

```

Cleaning the To Read file. 
```{r}
url5 = "https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/refs/heads/master/to_read.csv"
to_read = read_csv(url5)

view(to_read)

```
Set Up (KB):
```{r}
library(readr)
library(dplyr)
```

Import data (JM):
```{r}
book_data = read_csv("Books.csv")
head(book_data)
```

Remove unnecessary variables (JM): 
```{r}
book_data = book_data %>%
  select(
    book_id,
    goodreads_book_id,  
    isbn,                
    authors,             
    title,               
    average_rating,      
    ratings_count,       
    work_ratings_count,  
    work_text_reviews_count, 
    ratings_1,           
    ratings_2,           
    ratings_3,           
    ratings_4,           
    ratings_5            
  )
```

Check for missing (JM): 
```{r}
missing_summary = book_data %>%
  summarise(across(everything(), ~ sum(is.na(.)), .names = "{.col}"))

print(missing_summary)
```
There are 700 entries missing from the 'missing_isbn' variable. 

Removing missing values (JM): 
```{r}
book_data_complete = book_data %>%
  filter(!is.na(isbn))
```

Creating new csv file for use (JM): 
```{r}
write.csv(book_data_complete, "book_data_complete.csv", row.names = FALSE)
```


Creating merged tag file (SR)
```{r}
merged_tags = 
  left_join(book_tag, tags, by = c("tag_id")) %>%
  group_by(goodreads_book_id) %>%
  arrange(desc(count)) %>%
  slice_head(n = 5) %>%
  ungroup()
  

pivoted_data <- merged_tags %>%
  mutate(rank = row_number(), .by = goodreads_book_id) %>% # Add rank for top tags
  pivot_wider(
    id_cols = goodreads_book_id, 
    names_from = rank, 
    values_from = c(tag_name), 
    names_prefix = "top_"
  )


books_with_tags <- left_join(book_data_complete, pivoted_data, by = c("goodreads_book_id"))

write.csv(books_with_tags, "books_with_tags.csv", row.names = FALSE)
```